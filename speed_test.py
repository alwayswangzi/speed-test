#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import logging
import json
import socket
import requests
from typing import Dict, Generator, Any, List, Tuple
from flask import Flask, render_template, jsonify, request, Response
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# æ–‡ä»¶å¤§å°é…ç½® (key: æ ‡è¯†ç¬¦, value: å­—èŠ‚æ•°)
FILE_SIZES: Dict[str, int] = {
    "1m": 1 * 1024 * 1024,      # 1MB - å¿«é€Ÿæµ‹è¯•
    "10m": 10 * 1024 * 1024,    # 10MB - æ ‡å‡†æµ‹è¯•
    "50m": 50 * 1024 * 1024,    # 50MB - è¯¦ç»†æµ‹è¯• (é»˜è®¤)
    "100m": 100 * 1024 * 1024   # 100MB - å‹åŠ›æµ‹è¯•
}

# æµå¼ç”Ÿæˆé…ç½®
CHUNK_SIZE = 64 * 1024  # 64KB chunks for optimal streaming performance
DEFAULT_SIZE = "50m"     # é»˜è®¤æ–‡ä»¶å¤§å°

# Pingæµ‹è¯•é…ç½®
PING_TEST_COUNT = 5    # pingæµ‹è¯•æ¬¡æ•°

# ç½‘ç«™è¿é€šæ€§æµ‹è¯•é…ç½®
WEBSITE_TEST_TIMEOUT = 10  # ç½‘ç«™æµ‹è¯•è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
COMMON_WEBSITES = {
    "google": {
        "name": "Google",
        "url": "https://www.google.com",
        "description": "å…¨çƒæœ€å¤§æœç´¢å¼•æ“"
    },
    "youtube": {
        "name": "YouTube", 
        "url": "https://www.youtube.com",
        "description": "å…¨çƒæœ€å¤§è§†é¢‘å¹³å°"
    },
    "telegram": {
        "name": "Telegram",
        "url": "https://web.telegram.org",
        "description": "å³æ—¶é€šè®¯åº”ç”¨"
    },
    "github": {
        "name": "GitHub",
        "url": "https://github.com",
        "description": "ä»£ç æ‰˜ç®¡å¹³å°"
    },
    "stackoverflow": {
        "name": "Stack Overflow",
        "url": "https://stackoverflow.com",
        "description": "ç¨‹åºå‘˜é—®ç­”ç¤¾åŒº"
    },
    "baidu": {
        "name": "ç™¾åº¦",
        "url": "https://www.baidu.com",
        "description": "ä¸­å›½æœ€å¤§æœç´¢å¼•æ“"
    }
}


def generate_random_data_stream(file_size: int) -> Generator[bytes, None, None]:
    """
    ç”Ÿæˆéšæœºæ•°æ®æµï¼Œä¸ä¿å­˜åˆ°ç£ç›˜
    
    Args:
        file_size: è¦ç”Ÿæˆçš„æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        
    Yields:
        bytes: éšæœºæ•°æ®å—
        
    Note:
        ä½¿ç”¨64KBåˆ†å—ç”Ÿæˆï¼Œå¹³è¡¡å†…å­˜ä½¿ç”¨å’Œæ€§èƒ½
    """
    remaining = file_size
    
    while remaining > 0:
        # ç”Ÿæˆéšæœºæ•°æ®å—
        current_chunk_size = min(CHUNK_SIZE, remaining)
        try:
            data = os.urandom(current_chunk_size)
            remaining -= current_chunk_size
            yield data
        except OSError as e:
            logger.error(f"ç”Ÿæˆéšæœºæ•°æ®å¤±è´¥: {e}")
            break




def test_website_connectivity(url: str, timeout: int = WEBSITE_TEST_TIMEOUT) -> Dict[str, Any]:
    """
    æµ‹è¯•ç½‘ç«™è¿é€šæ€§å’Œå“åº”æ—¶é—´
    
    Args:
        url: è¦æµ‹è¯•çš„ç½‘ç«™URL
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
    Returns:
        Dict: æµ‹è¯•ç»“æœ
    """
    result = {
        "url": url,
        "accessible": False,
        "response_time_ms": 0,
        "status_code": None,
        "error": None,
        "timestamp": datetime.now().isoformat()
    }
    
    try:
        start_time = time.time()
        response = requests.get(url, timeout=timeout, allow_redirects=True)
        end_time = time.time()
        
        response_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        result.update({
            "accessible": True,
            "response_time_ms": round(response_time, 2),
            "status_code": response.status_code
        })
        
        logger.info(f"ç½‘ç«™è¿é€šæ€§æµ‹è¯•æˆåŠŸ: {url} - {response_time:.2f}ms (çŠ¶æ€ç : {response.status_code})")
        
    except requests.exceptions.Timeout:
        result["error"] = "è¿æ¥è¶…æ—¶"
        logger.warning(f"ç½‘ç«™è¿é€šæ€§æµ‹è¯•è¶…æ—¶: {url}")
    except requests.exceptions.ConnectionError:
        result["error"] = "è¿æ¥å¤±è´¥"
        logger.warning(f"ç½‘ç«™è¿é€šæ€§æµ‹è¯•è¿æ¥å¤±è´¥: {url}")
    except requests.exceptions.RequestException as e:
        result["error"] = f"è¯·æ±‚é”™è¯¯: {str(e)}"
        logger.warning(f"ç½‘ç«™è¿é€šæ€§æµ‹è¯•è¯·æ±‚é”™è¯¯: {url} - {e}")
    except Exception as e:
        result["error"] = f"æœªçŸ¥é”™è¯¯: {str(e)}"
        logger.error(f"ç½‘ç«™è¿é€šæ€§æµ‹è¯•æœªçŸ¥é”™è¯¯: {url} - {e}")
    
    return result


def test_all_websites() -> Dict[str, Any]:
    """
    æµ‹è¯•æ‰€æœ‰é…ç½®çš„ç½‘ç«™è¿é€šæ€§
    
    Returns:
        Dict: æ‰€æœ‰ç½‘ç«™çš„æµ‹è¯•ç»“æœ
    """
    results = {
        "websites": {},
        "summary": {
            "total": len(COMMON_WEBSITES),
            "accessible": 0,
            "failed": 0,
            "average_response_time": 0
        },
        "timestamp": datetime.now().isoformat()
    }
    
    accessible_count = 0
    total_response_time = 0
    
    for key, site_info in COMMON_WEBSITES.items():
        logger.info(f"å¼€å§‹æµ‹è¯•ç½‘ç«™: {site_info['name']} ({site_info['url']})")
        
        test_result = test_website_connectivity(site_info['url'])
        test_result.update({
            "name": site_info['name'],
            "description": site_info['description']
        })
        
        results["websites"][key] = test_result
        
        if test_result["accessible"]:
            accessible_count += 1
            total_response_time += test_result["response_time_ms"]
    
    # è®¡ç®—æ±‡æ€»ä¿¡æ¯
    results["summary"]["accessible"] = accessible_count
    results["summary"]["failed"] = len(COMMON_WEBSITES) - accessible_count
    
    if accessible_count > 0:
        results["summary"]["average_response_time"] = round(total_response_time / accessible_count, 2)
    
    logger.info(f"ç½‘ç«™è¿é€šæ€§æµ‹è¯•å®Œæˆ: {accessible_count}/{len(COMMON_WEBSITES)} ä¸ªç½‘ç«™å¯è®¿é—®")
    
    return results


def calculate_ping_stats(pings: List[float]) -> Dict[str, float]:
    """
    è®¡ç®—pingç»Ÿè®¡ä¿¡æ¯
    
    Args:
        pings: pingæ—¶å»¶åˆ—è¡¨ï¼ˆæ¯«ç§’ï¼‰
        
    Returns:
        Dict: pingç»Ÿè®¡ä¿¡æ¯
    """
    if not pings:
        return {
            "min": 0,
            "max": 0,
            "avg": 0,
            "median": 0,
            "jitter": 0
        }
    
    pings.sort()
    min_ping = pings[0]
    max_ping = pings[-1]
    avg_ping = sum(pings) / len(pings)
    
    # è®¡ç®—ä¸­ä½æ•°
    n = len(pings)
    if n % 2 == 0:
        median_ping = (pings[n//2-1] + pings[n//2]) / 2
    else:
        median_ping = pings[n//2]
    
    # è®¡ç®—æŠ–åŠ¨ï¼ˆæ ‡å‡†å·®ï¼‰
    variance = sum((x - avg_ping) ** 2 for x in pings) / len(pings)
    jitter = variance ** 0.5
    
    return {
        "min": round(min_ping, 2),
        "max": round(max_ping, 2),
        "avg": round(avg_ping, 2),
        "median": round(median_ping, 2),
        "jitter": round(jitter, 2)
    }


@app.route("/")
def index():
    """ä¸»é¡µé¢"""
    logger.info("ç”¨æˆ·è®¿é—®ä¸»é¡µé¢")
    return render_template("index.html")


@app.route("/download")
def download_file():
    """
    æä¾›æ–‡ä»¶ä¸‹è½½ - ä½¿ç”¨æµå¼ç”Ÿæˆï¼Œä¸ä¿å­˜æ–‡ä»¶
    
    Query Parameters:
        size: æ–‡ä»¶å¤§å°æ ‡è¯†ç¬¦ (é»˜è®¤: 50m)
        
    Returns:
        Response: æµå¼ä¸‹è½½å“åº”
    """
    file_size_key = request.args.get("size", DEFAULT_SIZE)
    file_size = FILE_SIZES.get(file_size_key, FILE_SIZES[DEFAULT_SIZE])
    
    logger.info(f"å¼€å§‹ç”Ÿæˆ {file_size / (1024*1024):.1f}MB éšæœºæ•°æ®æµ (key: {file_size_key})")
    
    # åˆ›å»ºå“åº”æµ
    def generate():
        """å†…éƒ¨ç”Ÿæˆå™¨å‡½æ•°"""
        try:
            data_stream = generate_random_data_stream(file_size)
            for chunk in data_stream:
                yield chunk
        except Exception as e:
            logger.error(f"æ•°æ®æµç”Ÿæˆé”™è¯¯: {e}")
            yield b""
    
    # è¿”å›æµå¼å“åº”
    response = Response(
        generate(),
        mimetype="application/octet-stream",
        headers={
            "Content-Disposition": f"attachment; filename=test_data_{file_size_key}.bin",
            "Content-Length": str(file_size),
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Expires": "0"
        }
    )
    
    return response




@app.route("/api/file-sizes")
def get_file_sizes():
    """
    è¿”å›æ‰€æœ‰å¯ç”¨çš„æ–‡ä»¶å¤§å°é€‰é¡¹
    
    Returns:
        JSON: æ–‡ä»¶å¤§å°é€‰é¡¹åˆ—è¡¨
    """
    sizes = []
    for key, size_bytes in FILE_SIZES.items():
        sizes.append({
            "key": key,
            "size_bytes": size_bytes,
            "size_mb": round(size_bytes / (1024 * 1024), 2),
            "display_name": f"{round(size_bytes / (1024 * 1024), 2)} MB"
        })
    
    logger.info(f"è¿”å› {len(sizes)} ä¸ªæ–‡ä»¶å¤§å°é€‰é¡¹")
    return jsonify({"sizes": sizes})


@app.route("/api/ping")
def ping():
    """
    ç®€å•çš„pingæµ‹è¯•ï¼Œè¿”å›æœåŠ¡å™¨å“åº”æ—¶é—´
    
    Returns:
        JSON: pingç»“æœ
    """
    start_time = time.time()
    
    # ç®€å•çš„å“åº”
    response_data = {
        "status": "ok",
        "message": "pong",
        "timestamp": datetime.now().isoformat(),
        "server_time": time.time()
    }
    
    end_time = time.time()
    response_time = (end_time - start_time) * 1000
    
    response_data["response_time_ms"] = round(response_time, 2)
    
    logger.info(f"Pingæµ‹è¯•: {response_time:.2f}ms")
    return jsonify(response_data)


@app.route("/api/website-test")
def website_test():
    """
    æµ‹è¯•å¸¸ç”¨ç½‘ç«™çš„è¿é€šæ€§å’Œå»¶æ—¶
    
    Returns:
        JSON: ç½‘ç«™è¿é€šæ€§æµ‹è¯•ç»“æœ
    """
    logger.info("å¼€å§‹ç½‘ç«™è¿é€šæ€§æµ‹è¯•")
    
    try:
        results = test_all_websites()
        logger.info(f"ç½‘ç«™è¿é€šæ€§æµ‹è¯•å®Œæˆ: {results['summary']['accessible']}/{results['summary']['total']} ä¸ªç½‘ç«™å¯è®¿é—®")
        return jsonify(results)
    except Exception as e:
        logger.error(f"ç½‘ç«™è¿é€šæ€§æµ‹è¯•å¤±è´¥: {e}")
        return jsonify({
            "error": f"ç½‘ç«™è¿é€šæ€§æµ‹è¯•å¤±è´¥: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }), 500


@app.route("/api/websites")
def get_websites():
    """
    è¿”å›æ‰€æœ‰å¯æµ‹è¯•çš„ç½‘ç«™åˆ—è¡¨
    
    Returns:
        JSON: ç½‘ç«™åˆ—è¡¨
    """
    websites = []
    for key, site_info in COMMON_WEBSITES.items():
        websites.append({
            "key": key,
            "name": site_info['name'],
            "url": site_info['url'],
            "description": site_info['description']
        })
    
    logger.info(f"è¿”å› {len(websites)} ä¸ªå¯æµ‹è¯•ç½‘ç«™")
    return jsonify({"websites": websites})


@app.errorhandler(404)
def not_found(error):
    """404é”™è¯¯å¤„ç†"""
    logger.warning(f"404é”™è¯¯: {request.url}")
    return jsonify({"error": "é¡µé¢æœªæ‰¾åˆ°"}), 404


@app.errorhandler(500)
def internal_error(error):
    """500é”™è¯¯å¤„ç†"""
    logger.error(f"500é”™è¯¯: {error}")
    return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


def validate_configuration():
    """éªŒè¯é…ç½®"""
    if not FILE_SIZES:
        raise ValueError("FILE_SIZESé…ç½®ä¸èƒ½ä¸ºç©º")
    
    if DEFAULT_SIZE not in FILE_SIZES:
        raise ValueError(f"é»˜è®¤å¤§å° {DEFAULT_SIZE} ä¸åœ¨FILE_SIZESä¸­")
    
    logger.info("é…ç½®éªŒè¯é€šè¿‡")


def print_startup_info():
    """æ‰“å°å¯åŠ¨ä¿¡æ¯"""
    print("=" * 60)
    print("ğŸš€ ä¸‹è½½é€Ÿåº¦æµ‹è¯•æœåŠ¡å™¨")
    print("=" * 60)
    print(f"ğŸ“Š æ”¯æŒçš„æ–‡ä»¶å¤§å°: {', '.join([f'{size}MB' for size in [1, 10, 50, 100]])}")
    print(f"ğŸ¯ é»˜è®¤é€‰æ‹©: {FILE_SIZES[DEFAULT_SIZE] / (1024*1024):.0f}MB")
    print("è®¿é—®åœ°å€: http://localhost:5000")
    print("=" * 60)


if __name__ == "__main__":
    try:
        # éªŒè¯é…ç½®
        validate_configuration()
        
        # ç¡®ä¿templatesç›®å½•å­˜åœ¨
        os.makedirs("templates", exist_ok=True)
        
        # æ‰“å°å¯åŠ¨ä¿¡æ¯
        print_startup_info()
        
        # å¯åŠ¨æœåŠ¡å™¨
        app.run(host="0.0.0.0", port=5000, debug=False)
        
    except Exception as e:
        logger.error(f"æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        print(f"å¯åŠ¨å¤±è´¥: {e}")
        exit(1)